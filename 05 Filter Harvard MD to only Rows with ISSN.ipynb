{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harvard Data ISSN Filter Notebook\n",
    "\n",
    "This notebook processes the Harvard Data Excel file to keep only those rows where there are values in any of the following columns:\n",
    "- issn\n",
    "- issn_l\n",
    "- issn2\n",
    "- issn_other_online\n",
    "\n",
    "The notebook includes additional analysis of the filtered data and maintains all original columns in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import unicodedata\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import re\n",
    "\n",
    "# Configuration\n",
    "INPUT_FILE = 'Output Data/Harvard Data with LCC Subjects.xlsx'\n",
    "OUTPUT_FILE = 'Output Data/Harvard Data with LCC Subjects and only ISSN.xlsx'\n",
    "\n",
    "# ISSN-related columns to check\n",
    "ISSN_COLUMNS = ['issn', 'issn_l', 'issn2', 'issn_other_online']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging to handle Unicode\n",
    "def setup_logging():\n",
    "    \"\"\"Configure logging with both file and console handlers with Unicode support.\"\"\"\n",
    "    # Create logs directory if it doesn't exist\n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    \n",
    "    # Create formatters for different levels of detail\n",
    "    brief_formatter = logging.Formatter('%(message)s')\n",
    "    verbose_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "    # Create and configure handlers\n",
    "    log_filename = f\"logs/mods_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "    \n",
    "    # Clear any existing handlers\n",
    "    logger = logging.getLogger()\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)\n",
    "    \n",
    "    # File handler with UTF-8 encoding\n",
    "    file_handler = logging.FileHandler(log_filename, encoding='utf-8')\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    file_handler.setFormatter(verbose_formatter)\n",
    "    \n",
    "    # Console handler with system encoding\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    console_handler.setFormatter(brief_formatter)\n",
    "    \n",
    "    # Configure root logger\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_format_string(format_str):\n",
    "    \"\"\"Normalize format strings for consistent analysis.\"\"\"\n",
    "    if pd.isna(format_str):\n",
    "        return '[]'\n",
    "    \n",
    "    # Remove extra whitespace and normalize quotes\n",
    "    format_str = format_str.strip().replace(\"'\", '\"')\n",
    "    \n",
    "    # Ensure string is in list format\n",
    "    if not format_str.startswith('['):\n",
    "        format_str = f'[{format_str}]'\n",
    "    \n",
    "    # Normalize Unicode characters\n",
    "    format_str = unicodedata.normalize('NFKD', format_str)\n",
    "    \n",
    "    return format_str\n",
    "\n",
    "def load_excel_file(file_path):\n",
    "    \"\"\"Load Excel file and return DataFrame.\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Loading Excel file: {file_path}\")\n",
    "        df = pd.read_excel(file_path)\n",
    "        logger.info(f\"Successfully loaded {len(df)} rows\")\n",
    "        \n",
    "        # Normalize format strings if format column exists\n",
    "        if 'format' in df.columns:\n",
    "            df['format'] = df['format'].fillna('[]').astype(str).apply(normalize_format_string)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading file: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def validate_columns(df):\n",
    "    \"\"\"Validate that at least one ISSN column exists in the DataFrame.\"\"\"\n",
    "    existing_columns = [col for col in ISSN_COLUMNS if col in df.columns]\n",
    "    if not existing_columns:\n",
    "        raise ValueError(f\"None of the required ISSN columns {ISSN_COLUMNS} found in the file\")\n",
    "    logger.info(f\"Found ISSN columns: {existing_columns}\")\n",
    "    return existing_columns\n",
    "\n",
    "def analyze_issn_distribution(df, issn_columns):\n",
    "    \"\"\"Analyze the distribution of ISSN values across columns.\"\"\"\n",
    "    logger.info(\"\\nISSN Distribution Analysis:\")\n",
    "    \n",
    "    # Count non-null values in each ISSN column\n",
    "    for col in issn_columns:\n",
    "        count = df[col].notna().sum()\n",
    "        logger.info(f\"{col}: {count} values\")\n",
    "    \n",
    "    # Count rows with multiple ISSN values\n",
    "    multiple_issns = df[issn_columns].notna().sum(axis=1)\n",
    "    for i in range(2, len(issn_columns) + 1):\n",
    "        count = (multiple_issns == i).sum()\n",
    "        if count > 0:\n",
    "            logger.info(f\"Rows with {i} ISSN values: {count}\")\n",
    "\n",
    "def filter_rows_with_issn(df, issn_columns):\n",
    "    \"\"\"Filter DataFrame to keep only rows with values in any ISSN column.\"\"\"\n",
    "    # Create a mask for rows that have any ISSN value\n",
    "    mask = df[issn_columns].notna().any(axis=1)\n",
    "    \n",
    "    # Apply the mask and get filtered DataFrame\n",
    "    filtered_df = df[mask].copy()\n",
    "    \n",
    "    # Log the results\n",
    "    removed_rows = len(df) - len(filtered_df)\n",
    "    logger.info(f\"\\nFiltering Results:\")\n",
    "    logger.info(f\"Original rows: {len(df)}\")\n",
    "    logger.info(f\"Rows with ISSN values: {len(filtered_df)}\")\n",
    "    logger.info(f\"Rows removed: {removed_rows}\")\n",
    "    logger.info(f\"Percentage of rows kept: {(len(filtered_df)/len(df)*100):.2f}%\")\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "def analyze_metadata(df, filtered_df):\n",
    "    \"\"\"Analyze metadata characteristics of kept vs removed rows.\"\"\"\n",
    "    logger.info(\"\\nMetadata Analysis:\")\n",
    "    \n",
    "    # Analyze type distribution\n",
    "    if 'type' in df.columns:\n",
    "        logger.info(\"\\nType distribution in kept rows:\")\n",
    "        type_counts = filtered_df['type'].value_counts()\n",
    "        for type_name, count in type_counts.items():\n",
    "            logger.info(f\"{type_name}: {count}\")\n",
    "    \n",
    "    # Analyze format distribution with proper handling of list-like strings\n",
    "    if 'format' in df.columns:\n",
    "        logger.info(\"\\nFormat distribution in kept rows (top 20):\")\n",
    "        format_counts = filtered_df['format'].value_counts().head(20)\n",
    "        \n",
    "        # Write full format distribution to a separate file\n",
    "        format_file = 'format_distribution.txt'\n",
    "        with open(format_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"Format Distribution (Full):\\n\\n\")\n",
    "            for format_name, count in filtered_df['format'].value_counts().items():\n",
    "                f.write(f\"{format_name}: {count}\\n\")\n",
    "        \n",
    "        # Log just the top 20 formats\n",
    "        for format_name, count in format_counts.items():\n",
    "            logger.info(f\"{format_name}: {count}\")\n",
    "        \n",
    "        logger.info(f\"\\nFull format distribution written to {format_file}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main processing function.\"\"\"\n",
    "    try:\n",
    "        # Load the data\n",
    "        df = load_excel_file(INPUT_FILE)\n",
    "        \n",
    "        # Validate columns\n",
    "        issn_columns = validate_columns(df)\n",
    "        \n",
    "        # Analyze ISSN distribution before filtering\n",
    "        analyze_issn_distribution(df, issn_columns)\n",
    "        \n",
    "        # Filter rows\n",
    "        filtered_df = filter_rows_with_issn(df, issn_columns)\n",
    "        \n",
    "        # Analyze metadata\n",
    "        analyze_metadata(df, filtered_df)\n",
    "        \n",
    "        # Save the filtered DataFrame\n",
    "        filtered_df.to_excel(OUTPUT_FILE, index=False)\n",
    "        logger.info(f\"\\nSaved filtered data to {OUTPUT_FILE}\")\n",
    "        \n",
    "        # Display sample of filtered data\n",
    "        logger.info(\"\\nSample of filtered data (first 5 rows):\")\n",
    "        display(filtered_df[['title'] + issn_columns].head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during processing: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Excel file: Output Data/Harvard Data with LCC Subjects.xlsx\n",
      "Successfully loaded 885565 rows\n",
      "Found ISSN columns: ['issn', 'issn_l', 'issn2', 'issn_other_online']\n",
      "\n",
      "ISSN Distribution Analysis:\n",
      "issn: 303561 values\n",
      "issn_l: 42623 values\n",
      "issn2: 149276 values\n",
      "issn_other_online: 7090 values\n",
      "Rows with 2 ISSN values: 173160\n",
      "Rows with 3 ISSN values: 3943\n",
      "Rows with 4 ISSN values: 5963\n",
      "\n",
      "Filtering Results:\n",
      "Original rows: 885565\n",
      "Rows with ISSN values: 303615\n",
      "Rows removed: 581950\n",
      "Percentage of rows kept: 34.28%\n",
      "\n",
      "Metadata Analysis:\n",
      "\n",
      "Type distribution in kept rows:\n",
      "serial: 303202\n",
      "monographic: 228\n",
      "integrating resource: 133\n",
      "unknown: 52\n",
      "\n",
      "Format distribution in kept rows (top 20):\n",
      "[\"probably print\"]: 79932\n",
      "[\"unknown\"]: 74411\n",
      "[\"probably print\", \"online resource\", \"computer\", \"electronic resource\", \"remote\"]: 62140\n",
      "[\"probably print\", \"online\"]: 24349\n",
      "[\"probably print\", \"computer\", \"online resource\"]: 23147\n",
      "[\"probably print\", \"volume\", \"unmediated\"]: 6775\n",
      "[\"probably print\", \"online\", \"volume\", \"unmediated\"]: 5391\n",
      "[\"computermedien\", \"online-ressource\", \"probably print\", \"electronic resource\", \"remote\"]: 4220\n",
      "[\"probably print\", \"remote\", \"electronic resource\"]: 3885\n",
      "[\"probably print\", \"microfilm\"]: 3212\n",
      "[\"online\", \"probably print\", \"online resource\", \"computer\", \"electronic resource\", \"remote\"]: 2695\n",
      "[\"online\"]: 1699\n",
      "[\"probably print\", \"microfilm\", \"volume\", \"unmediated\"]: 1207\n",
      "[\"probably print\", \"microfilm\", \"online\"]: 1017\n",
      "[\"probably print\", \"unmediated\"]: 852\n",
      "[\"probably print\", \"microfiche\"]: 830\n",
      "[\"volume\", \"online\", \"probably print\", \"unmediated\", \"microfilm\"]: 701\n",
      "[\"probably print\", \"electronic\", \"electronic resource\", \"remote\"]: 659\n",
      "[\"microfilm\"]: 506\n",
      "[\"probably print\", \"electronic resource\"]: 453\n",
      "\n",
      "Full format distribution written to format_distribution.txt\n",
      "\n",
      "Saved filtered data to Output Data/Harvard Data with LCC Subjects and only ISSN.xlsx\n",
      "\n",
      "Sample of filtered data (first 5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>issn</th>\n",
       "      <th>issn_l</th>\n",
       "      <th>issn2</th>\n",
       "      <th>issn_other_online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Teḥumin</td>\n",
       "      <td>0333-6883</td>\n",
       "      <td>0333-6883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Accessions list, Israel</td>\n",
       "      <td>0041-7750</td>\n",
       "      <td>0041-7750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Taḳtsiv leʾumi</td>\n",
       "      <td>0334-4738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Shenaton hidrologi le-Yisrael</td>\n",
       "      <td>0073-4217</td>\n",
       "      <td>0073-4217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Duḥot biḳoret ʻal igudim</td>\n",
       "      <td>0792-7932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title       issn     issn_l issn2  \\\n",
       "8                          Teḥumin  0333-6883  0333-6883   NaN   \n",
       "104        Accessions list, Israel  0041-7750  0041-7750   NaN   \n",
       "149                 Taḳtsiv leʾumi  0334-4738        NaN   NaN   \n",
       "191  Shenaton hidrologi le-Yisrael  0073-4217  0073-4217   NaN   \n",
       "198       Duḥot biḳoret ʻal igudim  0792-7932        NaN   NaN   \n",
       "\n",
       "    issn_other_online  \n",
       "8                 NaN  \n",
       "104               NaN  \n",
       "149               NaN  \n",
       "191               NaN  \n",
       "198               NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the main processing\n",
    "if __name__ == \"__main__\":\n",
    "    logger = setup_logging()\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
